# SC1015_DSAI_Project

The K-Nearest Neighbors (KNN) Classifier is a simple, yet effective, algorithm that classifies new data points based on the majority vote of its 'k' nearest neighbors. It is a type of instance-based learning where the function is only approximated locally, and all computation is deferred until function evaluation. 
 
 
 
 
Usage 
Before diving into the notebook, ensure that all necessary libraries and dependencies are installed as listed in the initial setup cells. Commence by loading the dataset, proceed through the notebook for data processing, exploratory analysis, model training, and evaluation, and culminate by deploying the model to predict stroke risk. 
 
 
References - 
 
 
http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html 
https://keras.io/ 
https://plotly.com/python/ 
https://scikit-learn.org/stable/modules/svm.html 
https://towardsdatascience.com/mac 
hine-learning-basics-with-the-k-nearest-neighbors-algorithm-6a6e71d01761 
https://scikit-learn.org/stable/modules/naive_bayes.html 
https://machinelearningmastery.com/gentle-introduction-xgboost-applied-machine-learning/ 
https://machinelearningmastery.com/introduction-to-regularization-to-reduce-overfitting-and-improve-generalization-error/ 
https://machinelearningmastery.com/rfe-feature-selection-in-python/ 
 
 
Authors 
 
Harineesh Reddy 
Gautham Krishna 
Gopashish Harikrishnan
